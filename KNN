#KNN Pipeline to determine best PCA, normalization and neighbors

pipelines = [
    ("PCA10", make_pipeline(StandardScaler(), PCA(n_components=10), KNeighborsClassifier())),
    ("PCA50", make_pipeline(StandardScaler(), PCA(n_components=50), KNeighborsClassifier())),
    ("PCA200", make_pipeline(StandardScaler(), PCA(n_components=200), KNeighborsClassifier())),
    ("PCA400", make_pipeline(StandardScaler(), PCA(n_components=400), KNeighborsClassifier())),
    ("Scaled", make_pipeline(StandardScaler(), KNeighborsClassifier())),
    ("Original", make_pipeline(KNeighborsClassifier())),
    ("10 Best", make_pipeline(SelectKBest(f_classif, k=10), KNeighborsClassifier())),
    ("Variance", make_pipeline(VarianceThreshold(threshold=.2), KNeighborsClassifier()))
]

neighbors = [10, 50, 80, 100, 150, 210]

best_val = -1
best_dataset = None
best_neighbor = None

for n in neighbors:
    for name, pipe in pipelines:

        pipe.set_params(kneighborsclassifier__n_neighbors=n)

        scores = cross_validate(
            pipe,
            X_train,
            y_train,
            cv=4,
            scoring={'accuracy': 'accuracy','roc_auc': 'roc_auc_ovr','f1': 'f1_macro'},
            return_train_score=True
        )
        train_mean = scores["train_accuracy"].mean()
        val_mean = scores["test_accuracy"].mean()
        auc = scores["test_roc_auc"].mean()
        f1 = scores["test_f1"].mean()


        print(f"{name}: neighbors={n}, Train={train_mean:.4f}, Val={val_mean:.4f}, AUC={auc:.4f}, F1={f1:.4f}")

        if val_mean > best_val:
            best_val = val_mean
            best_dataset = name
            best_neighbor = n

print("\nBest Model:")
print(f"Dataset: {best_dataset}, K={best_neighbor}, ValAcc={best_val:.4f}")


#gridsearch using best dataset
data = [X_pca50]
data_names = ["PCA 50"]

plt.figure(figsize=(10, 6))

for i, ds in enumerate(data):
    train_accuracies = []
    val_accuracies = []
    auc_accuracies = []
    f1_accuracies = []
    labels = []

    for k in range(1, 150):
        knn = KNeighborsClassifier(n_neighbors = k)
        scores = cross_validate(knn, ds, y_train, cv=4, scoring={'accuracy': 'accuracy','roc_auc': 'roc_auc_ovr','f1': 'f1_macro'}, return_train_score=True)

        train_mean = scores['train_accuracy'].mean()
        val_mean = scores['test_accuracy'].mean()
        auc = scores["test_roc_auc"].mean()
        f1 = scores["test_f1"].mean()


        train_accuracies.append(train_mean)
        val_accuracies.append(val_mean)
        auc_accuracies.append(auc)
        f1_accuracies.append(f1)

        print(f"K={k}, Train={train_mean:.4f}, Val={val_mean:.4f}, Difference={train_mean-val_mean:.4f}, auc={auc:.4f}, f1={f1:.4f}")

    plt.plot(range(1,150), val_accuracies, label = f"{data_names[i]} (Val)", color="blue")
    plt.plot(range(1,150), train_accuracies, label = f"{data_names[i]} (Train)",color="green")
    plt.plot(range(1,150), auc_accuracies, label = "AUC of ROC", color = "pink")
    plt.plot(range(1,150), f1_accuracies, label = "F1", color = "purple")

plt.title("KNN: PCA 50")
plt.ylabel("Score")
plt.xlabel("Neighbors")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()


#evaluating each of the 4-folds to determine if overfitting
colors = ["red", "green", "purple", "yellow", "blue", "red", "orange", "pink", "black", "brown"]
x=0
neighbors = [25, 40, 54, 70, 85]
for i in neighbors:
  knn = KNeighborsClassifier(n_neighbors = i)
  scores = cross_val_score(knn, X_pca50, y_train, cv=4)
  print(f"{i} Neighbors: {scores}")
  plt.plot(range(1,5), scores, label = f"{i} Neighbors", color = colors[x])
  x+=1
plt.title("KNN 4 Fold Scores")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xlabel("Fold")
plt.ylabel("Accuracy")
cross_val_score(knn, X_pca50, y_train, cv=4)
